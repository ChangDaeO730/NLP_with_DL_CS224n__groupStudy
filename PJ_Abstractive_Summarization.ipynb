{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\0a\\9e\\ba\\20e5bbc1afef3a491f0b3bb74d508f99403aabe76eda2167ca\\bs4-0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages (from bs4) (4.6.0)\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "\n",
    "# seed 고정 함수\n",
    "def seed_everything(seed = 42):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/user/study/NLP_tutorial/dataset/Reviews.csv\", nrows = 200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n",
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "                                                Text                Summary\n",
      "0  I have bought several of the Vitality canned d...  Good Quality Dog Food\n",
      "1  Product arrived labeled as Jumbo Salted Peanut...      Not as Advertised\n",
      "2  This is a confection that has been around a fe...  \"Delight\" says it all\n",
      "3  If you are looking for the secret ingredient i...         Cough Medicine\n",
      "4  Great taffy at a great price.  There was a wid...            Great taffy\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "print(data.columns)\n",
    "data = data[['Text', 'Summary']]\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>182531</th>\n",
       "      <td>Kind Healthy Grains Vanilla Blueberry Clusters...</td>\n",
       "      <td>Very crunchy, but a not as tasty as I expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40369</th>\n",
       "      <td>I got these for my kids lunch snacks - our sch...</td>\n",
       "      <td>Great Lunch Snack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179090</th>\n",
       "      <td>I seldom write reviews, but this popcorn is so...</td>\n",
       "      <td>THIS POPCORN IS AMAZING!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86364</th>\n",
       "      <td>I like elderberry tea and this is a good tea t...</td>\n",
       "      <td>Wild Elderberry Tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18440</th>\n",
       "      <td>Ordered this for my mom's trick or treaters , ...</td>\n",
       "      <td>Nestle Assorted Miniatures</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96188</th>\n",
       "      <td>Even though I (thought) I hated them for 25 ye...</td>\n",
       "      <td>You can definitely taste the salt &amp; vinegar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185409</th>\n",
       "      <td>Wow, the olive flavor socked me from the first...</td>\n",
       "      <td>Great flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154844</th>\n",
       "      <td>I used a lot of this mix adding all sorts of t...</td>\n",
       "      <td>Cake mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166682</th>\n",
       "      <td>For a long time my one greyhound could not hav...</td>\n",
       "      <td>My hounds love these</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79904</th>\n",
       "      <td>And, if u do, use a fork!  It's that easy!  Bi...</td>\n",
       "      <td>U CAN't beat KRUSTEAZ!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  \\\n",
       "182531  Kind Healthy Grains Vanilla Blueberry Clusters...   \n",
       "40369   I got these for my kids lunch snacks - our sch...   \n",
       "179090  I seldom write reviews, but this popcorn is so...   \n",
       "86364   I like elderberry tea and this is a good tea t...   \n",
       "18440   Ordered this for my mom's trick or treaters , ...   \n",
       "96188   Even though I (thought) I hated them for 25 ye...   \n",
       "185409  Wow, the olive flavor socked me from the first...   \n",
       "154844  I used a lot of this mix adding all sorts of t...   \n",
       "166682  For a long time my one greyhound could not hav...   \n",
       "79904   And, if u do, use a fork!  It's that easy!  Bi...   \n",
       "\n",
       "                                               Summary  \n",
       "182531  Very crunchy, but a not as tasty as I expected  \n",
       "40369                                Great Lunch Snack  \n",
       "179090                        THIS POPCORN IS AMAZING!  \n",
       "86364                              Wild Elderberry Tea  \n",
       "18440                       Nestle Assorted Miniatures  \n",
       "96188      You can definitely taste the salt & vinegar  \n",
       "185409                                    Great flavor  \n",
       "154844                                        Cake mix  \n",
       "166682                            My hounds love these  \n",
       "79904                           U CAN't beat KRUSTEAZ!  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing & EDA\n",
    "---\n",
    "* 중복데이터 제거\n",
    "* 결측치 제거\n",
    "* 약어 처리 (뜻은 같은데 표기가 짧은 단어)\n",
    "* 불용어 처리\n",
    "\n",
    "<BR/>\n",
    "\n",
    "* 데이터 길이분포 확인\n",
    "* 모델링을 위해 문장길이 통일\n",
    "  * 최대길이 설정하고 부족하면 패딩, 초과되면 관측삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열 중 유일값 :  162842\n",
      "summary 열 중 유일값 :  128912\n"
     ]
    }
   ],
   "source": [
    "# 중복값 확인\n",
    "print(\"text 열 중 유일값 : \", data['Text'].nunique())\n",
    "print(\"summary 열 중 유일값 : \", data['Summary'].nunique())\n",
    "\n",
    "# summary문의 경우 문장자체가 매우 짧아 겹칠 수 있다고 가정. 원문(text)이 겹치는 경우만 솎아주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남은 전체 샘플수 : 162842\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['Text'], inplace = True)\n",
    "print(\"남은 전체 샘플수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text       0\n",
       "Summary    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측값 확인\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측값을 포함한 관측 제거\n",
    "data.dropna(axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남은 전체 샘플수 : 162841\n"
     ]
    }
   ],
   "source": [
    "print(\"남은 전체 샘플수 :\", len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동의어 처리를 위한 dictionary\n",
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "{'did', 'mustn', 'weren', 'if', \"wouldn't\", 'off', 'needn', 'in', 'between', \"you'd\", 'below', \"weren't\", 'other', 'how', 'o', 'them', 'was', 'not', 'by', \"aren't\", \"mustn't\", 'such', \"that'll\", 'few', 'own', \"shan't\", 'to', 'from', 'so', 'most', 'under', 'is', 'as', 'over', 'her', 'further', \"should've\", \"doesn't\", 'been', \"hadn't\", 'myself', 'an', 'into', 've', 'shan', \"needn't\", 'he', 'has', 'it', 'until', 'above', \"couldn't\", \"shouldn't\", 'because', 'during', 'while', 'at', 'd', \"haven't\", 'its', 'didn', 'aren', 'after', 'himself', 'hers', 'shouldn', \"isn't\", 'out', 'each', 'won', 'which', 'your', 'why', 'wouldn', 'isn', \"wasn't\", 'being', 'but', 'what', 'a', \"didn't\", 'about', 'having', 'my', 'y', 'than', 'hasn', 'should', 'theirs', 'who', 'yours', 'can', \"you'll\", 'we', 'ma', 'this', 'again', 'more', 'down', 'yourselves', 'before', 'will', 'our', 'for', \"don't\", 'the', 'have', 'all', 'or', 'very', 're', \"you've\", 'here', 'am', 'up', 'mightn', 'haven', 'couldn', 'ourselves', 'their', 'had', 'now', 'through', 'where', 'they', 'whom', 'are', 'that', 'with', 'against', 'when', 'nor', 'hadn', 'too', 'and', 'no', 'there', \"it's\", 'doing', 'same', 'does', 'm', 'ain', \"she's\", 'wasn', 'll', 'me', 'both', \"hasn't\", 'those', 'be', 'don', 'i', 't', 'yourself', 'themselves', 'him', 'on', 'ours', \"you're\", 'you', 'only', 'doesn', 'then', 'do', 'herself', 'once', 'these', 'were', 'of', 's', 'his', 'itself', 'just', \"mightn't\", \"won't\", 'she', 'any', 'some'}\n"
     ]
    }
   ],
   "source": [
    "# NLTK 불용어\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print('불용어 개수 :', len(stop_words))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리 함수 구축\n",
    "> * 문장전체를 소문자화\n",
    "* html 태그, 쌍따옴표, 소유격 제거\n",
    "* 괄호로 닫힌 부분 문자열 제거\n",
    "* 약어 정규화\n",
    "* 숫자, 특수문자 등 알파벳 외의 문자를 공백으로 변환\n",
    "* m이 3개 이상이면 2개로 변경 \n",
    "* 불용어 처리 (원문에서만 제거)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, remove_stopwords = True):\n",
    "    sentence = sentence.lower()                                # 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text            # html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence)              # 괄호로 닫힌 문자열 제거\n",
    "    sentence = re.sub('\"', '', sentence)                       # 쌍따옴표 제거\n",
    "    # 약어 정규화\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")])\n",
    "    sentence = re.sub(r\"'s\\b\",\"\",sentence)                     # 소유격 제거\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)              # 영어 외 문자(숫자, 특수문자) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence)               # m이 3개 이상이면 2개로 변경\n",
    "    \n",
    "    # 불용어 처리\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1) \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br /> for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "print(preprocess_sentence(temp_summary, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 1, 5]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6]\n",
    "random.sample(a, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plus good deal price love convenience free delivery subscribe save saves money son ate always stock stores online good buy like ounce size containers minuses son gets constipated rice cereal oatmeal much better uses much breast milk mixing together mix directions right consistency feed baby would buy one package first see child reacts rice buy pack like',\n",
       " 'love coffee way need one machines bought first one years ago visiting relative recently bought second one motorhome yeah really like coffee way dependable easy clean',\n",
       " 'work dollar general sell dollar walmart sells like either place buy saving money paying shipping overcharge',\n",
       " 'finding delicious little packages fruit score perfect go snack apple apricot favorite flavor',\n",
       " 'quaker oats staple family generations oatmeal maternal grandmother prepared although always used old fashioned oatmeal actually cooked alive today know would tried quaker instant oatmeal packets prepared according package directions oatmeal comes smooth lumps found brown sugar taste acceptable usual maple flavor find authentic bit aftertaste packet one serving find sufficient whole breakfast adding toast fruit bacon sausage side makes meal stay hour two packets convenient campers hikers vacationers office workers take much room prepared quickly hot water available eaten plain without milk still quick meal snack']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text column 전처리\n",
    "clean_text = []\n",
    "for s in data['Text']:   # series도 순회가능\n",
    "    clean_text.append(preprocess_sentence(s))\n",
    "    \n",
    "random.sample(clean_text, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'...'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b007i7yygy/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b000v9lq30/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "C:\\Users\\user\\anaconda3\\envs\\for_deep\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.amazon.com/gp/product/b001eq58fq/ref=cm_cr_rev_prod_title\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['fantastic',\n",
       " 'excellent coffee',\n",
       " 'the good reviews just mystify me',\n",
       " 'great smell brown water',\n",
       " 'good if you like flavored coffee']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary column 전처리\n",
    "clean_summary = []\n",
    "for s in data['Summary']:\n",
    "    clean_summary.append(preprocess_sentence(s, 0))\n",
    "\n",
    "random.sample(clean_summary, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 결과를 데이터프레임에 다시 저장\n",
    "data['Text'] = clean_text\n",
    "data['Summary'] = clean_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text         1\n",
      "Summary    141\n",
      "dtype: int64\n",
      "남은 전체 샘플수 : 162699\n"
     ]
    }
   ],
   "source": [
    "# 전처리 이후 소멸되머린 샘플을 NAN으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 해당 관측 제거\n",
    "data.dropna(axis = 0, inplace = True)\n",
    "print('남은 전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 1235\n",
      "텍스트의 평균 길이 : 38.47853397992612\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 28\n",
      "요약의 평균 길이 : 3.9920036386210116\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EDA\n",
    "plt.style.use(\"seaborn-dark\")\n",
    "\n",
    "# 원문과 요약문의 길이 분포\n",
    "text_len = [len(s.split()) for s in data['Text']]\n",
    "summary_len = [len(s.split()) for s in data['Summary']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('Summary')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Summary')\n",
    "plt.hist(summary_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins=40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "길이가 50이상인 샘플의 비율 = 0.7779797471152843\n",
      "길이가 8이상인 샘플의 비율 = 0.9439883076129476\n"
     ]
    }
   ],
   "source": [
    "# 문장길이 통일을 위한 최대길이 설정\n",
    "text_max_len = 50\n",
    "summary_max_len = 8\n",
    "\n",
    "def below_threshold_cnt(batch_data, threshold):\n",
    "    li = [len(s.split()) for s in batch_data if len(s.split()) <= threshold]\n",
    "    print('길이가 {}이상인 샘플의 비율 = {}'.format(threshold,len(li)/len(batch_data) ))\n",
    "\n",
    "below_threshold_cnt(data['Text'], text_max_len)\n",
    "below_threshold_cnt(data['Summary'], summary_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남은 전체 샘플수 : 121930\n"
     ]
    }
   ],
   "source": [
    "# 설정한 최대 길이 초과하는 관측들 삭제\n",
    "# -- series.apply( lambda(x:f(x)) )  --- series를 x(input)로 취해서 f(x)를 계산한 결과를 반환 \n",
    "data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n",
    "print('남은 전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparing for Training\n",
    "* decoder의 input, target을 정의하기위해 sos, eos 토큰 추가\n",
    "* 데이터 분리\n",
    "* 단어사전 및 룩업테이블 생성\n",
    "* empty samples 제거\n",
    "* 패딩을 통해 시퀀스 길이맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bought several vitality canned dog food produc...</td>\n",
       "      <td>good quality dog food</td>\n",
       "      <td>sostoken good quality dog food</td>\n",
       "      <td>good quality dog food eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
       "      <td>not as advertised</td>\n",
       "      <td>sostoken not as advertised</td>\n",
       "      <td>not as advertised eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>confection around centuries light pillowy citr...</td>\n",
       "      <td>delight says it all</td>\n",
       "      <td>sostoken delight says it all</td>\n",
       "      <td>delight says it all eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>looking secret ingredient robitussin believe f...</td>\n",
       "      <td>cough medicine</td>\n",
       "      <td>sostoken cough medicine</td>\n",
       "      <td>cough medicine eostoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great taffy great price wide assortment yummy ...</td>\n",
       "      <td>great taffy</td>\n",
       "      <td>sostoken great taffy</td>\n",
       "      <td>great taffy eostoken</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text                Summary  \\\n",
       "0  bought several vitality canned dog food produc...  good quality dog food   \n",
       "1  product arrived labeled jumbo salted peanuts p...      not as advertised   \n",
       "2  confection around centuries light pillowy citr...    delight says it all   \n",
       "3  looking secret ingredient robitussin believe f...         cough medicine   \n",
       "4  great taffy great price wide assortment yummy ...            great taffy   \n",
       "\n",
       "                    decoder_input                  decoder_target  \n",
       "0  sostoken good quality dog food  good quality dog food eostoken  \n",
       "1      sostoken not as advertised      not as advertised eostoken  \n",
       "2    sostoken delight says it all    delight says it all eostoken  \n",
       "3         sostoken cough medicine         cough medicine eostoken  \n",
       "4            sostoken great taffy            great taffy eostoken  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary 데이터에 sos 토큰과 eos 토큰을 추가\n",
    "data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')\n",
    "\n",
    "encoder_input = np.array(data['Text'])\n",
    "decoder_input = np.array(data['decoder_input'])\n",
    "decoder_target = np.array(data['decoder_target'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106142  79383 111053 ... 103694    860  15795]\n",
      "훈련 데이터의 개수 : 97544\n",
      "훈련 레이블의 개수 : 97544\n",
      "테스트 데이터의 개수 : 24386\n",
      "테스트 레이블의 개수 : 24386\n"
     ]
    }
   ],
   "source": [
    "## train test split\n",
    "# data shuffle\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "\n",
    "# split\n",
    "test_ratio = 0.2\n",
    "test_size = int(len(indices)*test_ratio)\n",
    "\n",
    "encoder_input_train = encoder_input[:-test_size]\n",
    "decoder_input_train = decoder_input[:-test_size]\n",
    "decoder_target_train = decoder_target[:-test_size]\n",
    "\n",
    "encoder_input_test = encoder_input[-test_size:]\n",
    "decoder_input_test = decoder_input[-test_size:]\n",
    "decoder_target_test = decoder_target[-test_size:]\n",
    "\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :',len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :',len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :',len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer()\n",
    "src_tokenizer.fit_on_texts(encoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary 크기 : 44047\n",
      "등장 빈도가 3번 이하인 단어의 수: 28981\n",
      "희귀 단어 비율: 65.79562739800667\n",
      "희귀 단어 출현 비율: 1.6857224744230799\n"
     ]
    }
   ],
   "source": [
    "# src_tokenizer.word_index : 파싱된 단어 각각이 정수에 맵핑된 dictionary\n",
    "# src_tokenizer.word_counts : 파싱된 단어 각각의 말뭉치 내 등장횟수\n",
    "threshold = 3\n",
    "n_tot_words = len(src_tokenizer.word_index)\n",
    "n_rare_words = 0\n",
    "tot_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "# 단어 / 빈도 순회\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    tot_freq = tot_freq + value\n",
    "\n",
    "    # 말뭉치 내 등장 횟수가 임계값 이하인 단어들 count\n",
    "    if(value <= threshold):\n",
    "        n_rare_words = n_rare_words + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('vocabulary 크기 :',n_tot_words)\n",
    "print(f'등장 빈도가 {threshold}번 이하인 단어의 수: {n_rare_words}')\n",
    "print(\"희귀 단어 비율:\", (n_rare_words / n_tot_words)*100)\n",
    "print(\"희귀 단어 출현 비율:\", (rare_freq / tot_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * Q1) 전체 vocabulary에서 희귀단어를 제외하여 truncate 하였는데 아래와 같이 남은 단어보다 더 작은 수를 num_words로 지정할 경우 나머지단어들은 어캐되는거? 빈도수 순으로 짤린다는데, 빈도수가 같으면 알파벳순으로 짤리는건가? -> 그런듯\n",
    "* Q2) train set으로 토크나이저를 fit하여 룩업테이블을 얻었는데, 이 경우 test input에만 있고 train input에는 없는 단어가 나올경우 어캐처리??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab = 15000\n",
    "src_tokenizer = Tokenizer(num_words = src_vocab) \n",
    "src_tokenizer.fit_on_texts(encoder_input_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 변환된 데이터셋은 수치 레이블(단어 id)을 담은 이중 리스트가 되며,<br/>\n",
    "어휘사전에 포함되어있지 않은 단어들이 등장할 경우 변환 후 시퀀스에 해당단어들은 제외된다.<br/><br/>\n",
    "토크나이저에 OOB샘플을 따로 매핑하도록 할 수는 없을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary 크기 : 14685\n",
      "등장 빈도가 3번 이하인 단어의 수: 10118\n",
      "희귀 단어 비율: 68.90023833844059\n",
      "희귀 단어 출현 비율: 3.2310053722179584\n"
     ]
    }
   ],
   "source": [
    "# 타겟 시퀀스(요약문)에 대해서도 동일한 작업 수행\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "\n",
    "threshold = 3\n",
    "n_tot_words = len(tar_tokenizer.word_index)\n",
    "n_rare_words = 0\n",
    "tot_freq = 0\n",
    "rare_freq = 0\n",
    "\n",
    "# 단어 / 빈도 순회\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    tot_freq = tot_freq + value\n",
    "\n",
    "    # 말뭉치 내 등장 횟수가 임계값 이하인 단어들 count\n",
    "    if(value <= threshold):\n",
    "        n_rare_words = n_rare_words + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('vocabulary 크기 :',n_tot_words)\n",
    "print(f'등장 빈도가 {threshold}번 이하인 단어의 수: {n_rare_words}')\n",
    "print(\"희귀 단어 비율:\", (n_rare_words / n_tot_words)*100)\n",
    "print(\"희귀 단어 출현 비율:\", (rare_freq / tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_vocab = 4000\n",
    "tar_tokenizer = Tokenizer(num_words = tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete empty samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1540\n",
      "삭제할 테스트 데이터의 개수 : 434\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :',len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :',len(drop_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남은 훈련 데이터의 개수 : 96004\n",
      "남은 테스트 데이터의 개수 : 23952\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('남은 훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('남은 테스트 데이터의 개수 :',len(encoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Model \n",
    "---\n",
    "seq2seq + attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 50, 200)      3000000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 50, 300), (N 601200      embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 50, 300), (N 721200      lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 200)    800000      input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 50, 300), (N 721200      lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 300),  601200      embedding_5[0][0]                \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_10[0][0]                    \n",
      "                                                                 lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_11[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 4000)   2404000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 9,029,100\n",
      "Trainable params: 9,029,100\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 200\n",
    "hidden_size = 300\n",
    "\n",
    "# encoder\n",
    "encoder_inputs = Input(shape = (text_max_len, ))\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "enc_lstm1 = LSTM(hidden_size, return_sequences = True, return_state = True, \n",
    "                 dropout = 0.4, recurrent_dropout = 0.4)\n",
    "enc_output1, state_h1, state_c1 = enc_lstm1(enc_emb)\n",
    "enc_lstm2 = LSTM(hidden_size, return_sequences = True, return_state = True, \n",
    "                 dropout = 0.4, recurrent_dropout = 0.4)\n",
    "enc_output2, state_h2, state_c2 = enc_lstm2(enc_output1)\n",
    "enc_lstm3 = LSTM(hidden_size, return_sequences = True, return_state = True, \n",
    "                 dropout = 0.4, recurrent_dropout = 0.4)\n",
    "enc_outputs, state_h, state_c = enc_lstm3(enc_output2)\n",
    "\n",
    "# decoder\n",
    "decoder_inputs = Input(shape = (None, ))\n",
    "dec_emb = Embedding(tar_vocab, embedding_dim)(decoder_inputs)\n",
    "\n",
    "\n",
    "dec_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, \n",
    "                    dropout = 0.4, recurrent_dropout=0.2)\n",
    "dec_outputs, _, _ = dec_lstm(dec_emb, initial_state = [state_h, state_c])\n",
    "\n",
    "# ------------------------------------------------ 일반적인 출력층\n",
    "# # output of decoder\n",
    "# dec_softmax_layer = Dense(tar_vocab, activation = 'softmax')\n",
    "# dec_softmax_outputs = dec_softmax_layer(dec_outputs) \n",
    "\n",
    "# # model define\n",
    "# model = Model([encoder_inputs, decoder_inputs], dec_softmax_outputs)\n",
    "# model.summary()\n",
    "# ------------------------------------------------ 어텐션 이용 출력층\n",
    "# attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([enc_outputs, dec_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "dec_concat_output = Concatenate(axis = -1, name='concat_layer')([dec_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "dec_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = dec_softmax_layer(dec_concat_output)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96004 samples, validate on 23952 samples\n",
      "Epoch 1/50\n",
      "96004/96004 [==============================] - 8748s 91ms/sample - loss: 2.7379 - val_loss: 2.5011\n",
      "Epoch 2/50\n",
      "96004/96004 [==============================] - 5533s 58ms/sample - loss: 2.3680 - val_loss: 2.2660\n",
      "Epoch 3/50\n",
      "96004/96004 [==============================] - 5640s 59ms/sample - loss: 2.2050 - val_loss: 2.1671\n",
      "Epoch 4/50\n",
      "25344/96004 [======>.......................] - ETA: 1:02:00 - loss: 2.1170WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-433c6cc182d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder_target_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_target_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m                     batch_size = 256, callbacks = [es], epochs = 50)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\for_deep\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", verbose = 1, patience = 2)\n",
    "history = model.fit(x = [encoder_input_train, decoder_input_train], \n",
    "                    y = decoder_target_train,\n",
    "                    validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "                    batch_size = 256, callbacks = [es], epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/user/study/NLP_tutorial/saved_model/enc_dec_epoch3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'], label='train')\n",
    "# plt.plot(history.history['val_loss'], label='valid')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference\n",
    "encoder-decoder network에서 decoder의 behavior가 train시와 test시에 다르기 때문에 <br/>\n",
    "별도로 모델을 설계할 수 있다.\n",
    "> inference(test) 시에는 target sequence가 주어지지 않기때문에 sostoken만 인풋으로 받고<br/>\n",
    "각 시점의 출력을 이후 시점의 input으로 가져간다.<br/>\n",
    "또한 훈련시와는 다르게 디코더의 매시점 state vector들을 버리지 않고 이후 시점 input으로 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder \n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[enc_outputs, state_h, state_c])\n",
    "\n",
    "# decoder\n",
    "# 디코더의 이전시점 상태벡터(h, c)들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 =\\\n",
    "    dec_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "# attention function\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# final output\n",
    "decoder_outputs2 = dec_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if(sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 숫자 -> 텍스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 딕셔너리 정의\n",
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 :  use treats put kong toys give three labs something work leave work love especially like lamb salmon flavor nice soft treats break half make last longer \n",
      "정답 요약문 : great treats for treat toys \n",
      "예측 요약문 :  my my my for for\n",
      "\n",
      "\n",
      "원문 :  chips unbelievably good favorite salt pepper vinegar sea salt come close second taste like potato chips potato flavor greasy filled fat bland taste like cardboard recommended chips weight watchers group local organic store cannot keep demand hit guilt free snack lots flavor thank popchips \n",
      "정답 요약문 : awesome chips \n",
      "예측 요약문 :  popcorn chips chips chips chips chips\n",
      "\n",
      "\n",
      "원문 :  quick easy buying much easier going store mention convenient \n",
      "정답 요약문 : love this stuff \n",
      "예측 요약문 :  great and and to\n",
      "\n",
      "\n",
      "원문 :  coins hard take day half chew anise flavor licorice thing candy sweet comes adorable coin shapes great candy idea flavor texture need lot improvement \n",
      "정답 요약문 : cute terrible taste \n",
      "예측 요약문 :  of to sugar the in\n",
      "\n",
      "\n",
      "원문 :  used excellent kefir starter decades delicious consistant results time much much better store bought easy make cannot live happy without many people like better yogurt yogurt maker needed \n",
      "정답 요약문 : excellent kefir starter \n",
      "예측 요약문 :  of to to to to\n",
      "\n",
      "\n",
      "원문 :  owned two work fine power knob though biggest problem reason never purchase another gave year one sounds like recording behind wall one developed hum go away favor find reliable option \n",
      "정답 요약문 : too cheap \n",
      "예측 요약문 :  is but to in in\n",
      "\n",
      "\n",
      "원문 :  love curry pastes hot best flavor good easiest way make really good curry home little fuss little mess stuff served lamb potatoes carrots rice next day even better \n",
      "정답 요약문 : excellent flavor easiest curry ever \n",
      "예측 요약문 :  of and the the in\n",
      "\n",
      "\n",
      "원문 :  funny little coffee pods keurig give cups real run money great price high quality coffee work perfectly brewer tried fog chaser rainforest blend french roast like bold darker roasts pleased afraid try like lighter cup may tried breakfast blend continue buying happy product \n",
      "정답 요약문 : great product \n",
      "예측 요약문 :  of to coffee coffee coffee coffee\n",
      "\n",
      "\n",
      "원문 :  past bought local grocery store soft chewy moist delicious unfortunately batch received amazon dried crunchy stale wondering boxes sold expired overstock buyer beware food items returned hesitant try \n",
      "정답 요약문 : stale \n",
      "예측 요약문 :  of but in in in\n",
      "\n",
      "\n",
      "원문 :  product advertised fast ship good price likely buy long price stays good thanks \n",
      "정답 요약문 : product as advertised good price fast ship \n",
      "예측 요약문 :  is and and in\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"원문 : \",seq2text(encoder_input_test[i]))\n",
    "    print(\"정답 요약문 :\",seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약문 :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# 3에폭 성능 실화냐"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
